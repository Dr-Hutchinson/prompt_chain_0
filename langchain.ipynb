{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Calling the LLM***"
      ],
      "metadata": {
        "id": "aWvWXO4AMbjw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvayjFzVKqY4",
        "outputId": "76c9ddb4-17ad-4fd9-da39-726bce9c6686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.33-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.23.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.2)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.44)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.1)\n",
            "Installing collected packages: langchain\n",
            "Successfully installed langchain-0.0.33\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3-V0lxkKweN",
        "outputId": "fb866af5-9eea-4834-f251-9e3bef82a86b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 565 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=d0fd06d338a86fbb807b4046eb52e1330beb5e6abf753236c9d9433a39b3bd74\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "oiJtbnMAK0wg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "MoD_DCQVK7Kh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "I8cgtuwNK_DB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name a company that makes colorful socks?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I94NuaUvLB3N",
        "outputId": "d369f1cf-eab7-416a-ab68-d60df02924b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "BrightStep Socks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Constructing a Chain**"
      ],
      "metadata": {
        "id": "kG0r6gv5MjE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "CO1TF-tTMBSY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "0HIVnwCeMvoD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BIwlK4_XMwg8",
        "outputId": "459cefc6-ac2c-4452-bf87-ea143f178f28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nBrightFoots Sockery'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Sequential Chains**"
      ],
      "metadata": {
        "id": "Emh7GyBSM-XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "zBEpGLqXNDyH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an LLMChain to write a synopsis given a title of a play.\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "\n",
        "Title: {title}\n",
        "Playwright: This is a synopsis for the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "vqVAkkBbNIBm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an LLMChain to write a review of a play given a synopsis.\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "Play Synopsis:\n",
        "{synopsis}\n",
        "Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "WWkRXsPENLHA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the overall chain where we run these two chains in sequence.\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)"
      ],
      "metadata": {
        "id": "W2a3AKchNNMT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = overall_chain.run(\"Tragedy at sunset on the beach\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggf2WkbWNO7m",
        "outputId": "876e94a1-bbe3-40fb-b3fc-ffa6a47d430a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "The play, Tragedy at Sunset on the Beach, takes place on a sunny beach in the evening. A family of four, the parents and their two teenage children, have come to the beach to spend the evening together. The mother and father are happily reminiscing about their past, while their children are busy playing in the sand and enjoying the warmth of the sun. \n",
            "\n",
            "Suddenly, a storm begins to brew on the horizon and the family is forced to seek shelter. As they make their way to safety, the father slips and falls off a cliff, sacrificing his own life to save his family from the storm. The family is left in shock and grief, and the play follows them as they grapple with the sudden loss of their beloved father. The story culminates with the family coming to terms with their tragedy and learning to accept life's unpredictability.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "Theatergoers were moved to tears by the stunning performance of Tragedy at Sunset on the Beach. This powerful play follows a family who visits the beach for an evening of togetherness and fun, only to be met with a tragic accident. \n",
            "\n",
            "The cast of actors gave an outstanding performance, providing both an emotional and intense portrayal of the parents and their two teenage children. The mother and father's loving and nostalgic conversations gave the audience a sense of the family's closeness and joy, while the children's playful antics reminded us of the innocence of youth. \n",
            "\n",
            "The tragedy that befalls the family is heartbreaking, yet the play also emphasizes the importance of resilience and acceptance. The audience was captivated by the family's journey of grief and healing, and the actors successfully captured the raw emotions of the characters. \n",
            "\n",
            "Tragedy at Sunset on the Beach is a powerful play that will bring you to tears, but ultimately leave you with a feeling of hope. It is a must-see performance that will stay with you long after the curtain closes.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished SimpleSequentialChain chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Using Agents**"
      ],
      "metadata": {
        "id": "85MKDGucN1Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUQWnDthRRtX",
        "outputId": "36e445a1-3246-41b1-cd62-17ad2e799f07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.1.tar.gz (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from google-search-results) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->google-search-results) (1.24.3)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.1-py3-none-any.whl size=25788 sha256=77068ea089b694cb6352e39ebcded6243783a3ae806ee5e564f0cf9c3922065d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/58/9e/3d89ebff948ef9ce0a6e056a8279c1f93c76993387766f8387\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"02b51cceca14460c90cda6f21a42ce652bdb31950e1f49b499de8a09c5e11fa7\"\n",
        "\n",
        "#serpapi_key = \"02b51cceca14460c90cda6f21a42ce652bdb31950e1f49b499de8a09c5e11fa7\""
      ],
      "metadata": {
        "id": "G-eNvhR4O_Oh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SerpAPIWrapper\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "search = SerpAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.run\n",
        "    )\n",
        "]\n",
        "\n",
        "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)\n",
        "\n",
        "self_ask_with_search.run(\"What is the hometown of the reigning men's U.S. Open champion?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "kSowc0nLQbVg",
        "outputId": "a4abc675-90bd-4fda-ade2-8ff379926496"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SelfAskWithSearchAgent chain...\u001b[0m\n",
            "What is the hometown of the reigning men's U.S. Open champion?\n",
            "Are follow up questions needed here:\u001b[32;1m\u001b[1;3m Yes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mCarlos Alcaraz\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: Where is Carlos Alcaraz from?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mEl Palmar, Spain\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: El Palmar, Spain\u001b[0m\n",
            "\u001b[1m> Finished SelfAskWithSearchAgent chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El Palmar, Spain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Vector DB Question/Answering**"
      ],
      "metadata": {
        "id": "AYzDhURvTieQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEy9wv_lT9Ev",
        "outputId": "4fd33073-ec03-43b9-aa0c-02668fdc6774"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0 MB 2.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import OpenAI, VectorDBQA"
      ],
      "metadata": {
        "id": "N4FE2lRpTh-4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/raw_text_edited.txt') as f:\n",
        "    state_of_the_union = f.read()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(state_of_the_union)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "id": "58E_wXYJTq-x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = VectorDBQA(llm=OpenAI(), vectorstore=docsearch)"
      ],
      "metadata": {
        "id": "ler_p7BHTvhk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Are any ancient Romans mentioned in the text?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xYYpO9FnTyDC",
        "outputId": "09678fa8-f09d-44ec-ea63-6c8eb922e4ec"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' No, there are no ancient Romans mentioned in the text.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6 - Question-Answering with Sources**"
      ],
      "metadata": {
        "id": "jfakRlgIXUVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
        "from langchain.vectorstores.faiss import FAISS"
      ],
      "metadata": {
        "id": "M90pbQfmXY5m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/raw_text_edited.txt') as f:\n",
        "    state_of_the_union = f.read()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(state_of_the_union)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "wAn-ti51Xbje"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "id": "ws8aHAmyXhJN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add in a fake source information\n",
        "for i, d in enumerate(docsearch.docstore._dict.values()):\n",
        "    d.metadata = {'source': f\"{i}-pl\"}"
      ],
      "metadata": {
        "id": "nLQrkE39YKWj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Where was Edward IV buried?\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "ACAeA4U7XkM3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import QAWithSourcesChain\n",
        "from langchain.llms import OpenAI, Cohere\n",
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "ZGaLb7_bXqF6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = QAWithSourcesChain.from_llm(OpenAI(temperature=0))"
      ],
      "metadata": {
        "id": "wl-u32-CXs6M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"docs\": docs, \"question\": query}, return_only_outputs=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMp8XKzNXv3K",
        "outputId": "3560fb83-44c5-478f-c6e5-fec4199e1952"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': ' Edward IV was buried at Windsor.', 'sources': '1-pl'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step 7: Few Shot Prompting***"
      ],
      "metadata": {
        "id": "ZdZXk1JvdhM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "yWqSa4drdp2Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are some examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "]\n",
        "# This how we specify how the example should be formatted.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")"
      ],
      "metadata": {
        "id": "Q3Iphmrhdspk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"adjective\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\"\n",
        "\n",
        ")\n",
        "print(prompt_from_string_examples.format(adjective=\"big\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UgxxCzvdufR",
        "outputId": "4255fb1c-c5ba-4c24-dcb2-d4a0077b570f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: tall\n",
            "Output: short\n",
            "\n",
            "Input: big\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "CsjYlH8Pd-1u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_from_string_examples)"
      ],
      "metadata": {
        "id": "deTwn70d7Koc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"catstrophe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MvwVJq1h8Mmk",
        "outputId": "485e403a-9ffe-48de-f52a-0f4142d6e8ad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' success'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1 - PromptChain_0 - Few Shot Prompting for Text Identification - Three Outputs together**"
      ],
      "metadata": {
        "id": "1qFuNDplb2_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_text = \"What sort of personality did George have?\""
      ],
      "metadata": {
        "id": "MZqV7LTTcvfm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cell for running OpenAI embeddings on csv file.\n",
        "import csv\n",
        "from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "#from numpy import mean\n",
        "import numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
        "\n",
        "datafile_path = \"./more_index_embeddings.csv\"  # for your convenience, we precomputed the embeddings\n",
        "df = pd.read_csv(datafile_path)\n",
        "df[\"babbage_search\"] = df.babbage_search.apply(eval).apply(np.array)\n",
        "\n",
        "def search_text(df, product_description, n=3, pprint=True):\n",
        "            embedding = get_embedding(\n",
        "                product_description,\n",
        "                engine=\"text-search-babbage-query-001\"\n",
        "            )\n",
        "            df[\"similarities\"] = df.babbage_search.apply(lambda x: cosine_similarity(x, embedding))\n",
        "\n",
        "            res = (\n",
        "                df.sort_values(\"similarities\", ascending=False)\n",
        "                .head(n)\n",
        "                .combined\n",
        "                #.combined.str.replace(\"Summary: \", \"\")\n",
        "                #.str.replace(\"Text:\", \": \")\n",
        "            )\n",
        "            if pprint:\n",
        "                for r in res:\n",
        "                    print(r[:500])\n",
        "                    print()\n",
        "            return res\n",
        "\n",
        "res = search_text(df, submission_text, n=3)\n",
        "res_list = res.to_list()\n",
        "res_string = ' '.join(res_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-m5z2lwcAU4",
        "outputId": "c37bc438-8e2e-4824-a051-8951c8d40c23"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Section_3:  King Edward IV was a good-looking and strong man who was wise in counsel and just in war. He was also known for his love of women and good food. However, he was also known to be a fair and merciful man, and he was greatly loved by his people. Text: Section_3: He was a goodly personage, and very princely to behold: of heart, courageous; politic in counsel; in adversity nothing abashed; in prosperity, rather joyful than proud; in peace, just and merciful; in war, sharp and fie\n",
            "\n",
            "Summary: Section_7:  George, Duke of Clarence, was accused of treason and sentenced to death. He was drowned in a butt of malmesey, and his death was piteously bewailed by King Edward IV. Text: Section_7: George, Duke of Clarence, was a goodly noble prince, and at all points fortunate, if either his own ambition had not set him against his brother, or the envy of his enemies had not set his brother against him. For were it by the Queen and the lords of her blood, who highly maligned the King's k\n",
            "\n",
            "Summary: Section_9:  Some people think that King Edward IV had a hand in the death of his brother, George, the Duke of Clarence. They think that he did this because he wanted to be king himself, and George's death would clear the way for him to achieve this goal. However, there is no certainty about this, and it is just as likely that George's death was simply a coincidence. What is known for sure is that on the night of King Edward IV's death, one Mistlebrook came to the house of one Potter and\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKQ1mSL5H-oR",
        "outputId": "f576d533-c5eb-45a6-cfa6-bf1a95531d19"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Section_3:  King Edward IV was a good-looking and strong man who was wise in counsel and just in war. He was also known for his love of women and good food. However, he was also known to be a fair and merciful man, and he was greatly loved by his people. Text: Section_3: He was a goodly personage, and very princely to behold: of heart, courageous; politic in counsel; in adversity nothing abashed; in prosperity, rather joyful than proud; in peace, just and merciful; in war, sharp and fierce; in the field, bold and hardy, and nevertheless, no further than wisdom would, adventurous. Whose wars whosoever would well consider, he shall no less commend his wisdom when he withdrew than his manhood when he vanquished. He was of visage lovely, of body mighty, strong, and clean made; however, in his latter days with over-liberal diet , he became somewhat corpulent and burly, and nonetheless not uncomely; he was of youth greatly given to fleshly wantonness, from which health of body in great prosperity and fortune, without a special grace, hardly refrains. This fault not greatly grieved the people, for one man's pleasure could not stretch and extend to the displeasure of very many, and the fault was without violence, and besides that, in his latter days, it lessened and well left. Summary: Section_7:  George, Duke of Clarence, was accused of treason and sentenced to death. He was drowned in a butt of malmesey, and his death was piteously bewailed by King Edward IV. Text: Section_7: George, Duke of Clarence, was a goodly noble prince, and at all points fortunate, if either his own ambition had not set him against his brother, or the envy of his enemies had not set his brother against him. For were it by the Queen and the lords of her blood, who highly maligned the King's kindred (as women commonly, not of malice but of nature, hate them whom their husbands love), or were it a proud appetite of the Duke himself intending to be king, in any case, heinous treason was there laid to his charge, and, finally, were he faulty or were he faultless, attainted was he by Parliament and judged to the death, and thereupon hastily drowned in a butt of malmesey, whose death, King Edward (although he commanded it), when he knew it was done, piteously bewailed and sorrowfully repented Summary: Section_9:  Some people think that King Edward IV had a hand in the death of his brother, George, the Duke of Clarence. They think that he did this because he wanted to be king himself, and George's death would clear the way for him to achieve this goal. However, there is no certainty about this, and it is just as likely that George's death was simply a coincidence. What is known for sure is that on the night of King Edward IV's death, one Mistlebrook came to the house of one Potter and told him that the king was dead. Potter replied that this meant that his master, the Duke of Gloucester, would be the next king. It is not clear why Potter thought this, but it is possible that he knew something about the Duke's plans or had some inkling of them./n Text: Section_9: Some wise men also think that his plan�covertly conveyed�lacked not in helping his brother Clarence to his death, which he resisted openly, although somewhat (as men judged) more faintly than one who was heartily concerned for his welfare. And they who thus judged, they think he for a long time during King Edward's life forethought to be king in case the King his brother (whose life he looked to, so that evil diet should shorten it) should happen to die (as indeed he did) while his children were young. And they judged that for this reason: he was glad of his brother's death, that Duke of Clarence, whose life must needs have hindered his plans, whether the same Duke of Clarence had kept himself true to his nephew the young King, or enterprised to be king himself. But of all this point, is there no certainty, and whosoever divines upon conjectures may as well shoot too far as too short. However, this have I by credible information learned, that the same night in which King Edward died, one Mistlebrook, long before morning, came in great haste to the house of one Potter, dwelling in Redcross Street without Cripplegate, and when he was with hasty rapping quickly let in, he revealed unto Potter that King Edward was departed. By my truth man,� said Potter, then will my master the Duke of Gloucester be king.� What cause he had so to think it is hard to say: whether he, being well disposed toward him, knew anything about such a thing the Duke had purposed, or otherwise he had any inkling thereof, for he was not ever likely to speak of it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "-UUc1nOt89j1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are some examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "]\n",
        "# This how we specify how the example should be formatted.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")"
      ],
      "metadata": {
        "id": "kS3c4Qw_Bda2"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are some examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"question\": \"Question: Where was Edward IV buried?\", \"output\": \"Sections:\\nSummary: Section_160:  Sir James had the murderers bury King Edward V and Prince Richard's bodies deep in the ground under a heap of stones. Text: Section_160: Which after that the wretches perceived, first by the struggling with the pains of death, and after long lying still, to be thoroughly dead, they laid their bodies naked out upon the bed, and fetched Sir James to see them. Who, upon the sight of them, caused those murderers to bury them at the stair-foot, suitably deep in the ground, under a great heap of stones.\\nSummary: Section_1:  King Edward IV was a beloved king who was interred at Windsor with great honor. He was especially beloved by the people at the time of his death. Text: Section_1: This noble prince died at his palace of Westminster and, with great funeral honor and heaviness of his people from thence conveyed, was interred at Windsor. He was a king of such governance and behavior in time of peace (for in war each part must needs be another's enemy) that there was never any prince of this land attaining the crown by battle so heartily beloved by the substance of the people, nor he himself so specially in any part of his life as at the time of his death.\\nSummary: Section_16:  King Edward IV, on his deathbed, forgave those who had wronged him and asked them to forgive each other. However, it was apparent from their actions that their hearts were not truly in it.\\nText: Section_16: And therewithal, the King, no longer enduring to sit up, laid himself down on his right side, his face toward them, and none was there present that could refrain from weeping. But the lords, encouraging him with as good words as they could and answering for the time as they thought to stand with his pleasure, there in his presence (as by their words appeared), each forgave the other and joined their hands together, when (as it after appeared by their deeds) their hearts were far asunder.\\nRelevant Sections: Section_1 mentions Windsor at Edward IV's burial place. The other two sections do not mention Edward IV's burial place. \\nAnswer: Edward IV was interred at Windsor with great honor. 'This noble prince died at his palace of Westminster and, with great funeral honor and heaviness of his people from thence conveyed, was interred at Windsor.'(S.1)\\nExcellent. Let's try another.\"},\n",
        "    {\"question\": \"Question: What does the narrator think happened to the Princes in the Tower?\", \"output\": \"Sections:\\nSummary: Section_150:  I shall now tell you the sorrowful end of the two princes in the Tower. I have heard this story from many men, and I believe it to be true. Text: Section_150: But in the meantime, for this present matter, I shall rehearse you the sorrowful end of those babes, not after every way that I have heard, but after that way I have so heard by such men, and by such means, as I think it were hard but it should be true.\\nSummary: Section_149: King Richard III was responsible for the murder of his two nephews, Prince Edward and Prince Richard, in the Tower of London. This event has been disputed by many, as there was no clear evidence at the time. However, many people suspect that the two princes were killed on Richard's orders. Text: Section_149: Now fell their mischief thick. And as the thing evilly got is never well kept, through all the time of his reign there never ceased cruel death and slaughter, till his own destruction ended it. But as he finished his time with the best death and the most righteous, that is to say, his own, so began he with the most piteous and wicked: I mean the lamentable murder of his innocent nephews the young King and his tender brother, whose death and final misfortune has nevertheless so far come in question that some remain yet in doubt whether they were in his days destroyed or not. Not only because Perkin Warbeck by many folk's malice, and more folk's folly, so long a time spoiling the world was reputed and taken for the younger of those two, among princes as well as among the poorer people, but also because all things were in late days so covertly managed, one thing pretended and another meant, that there was nothing so plain and openly proved; but yet for the common custom of close and covert conduct, men ever inwardly had suspected the murders, just as many well-counterfeited jewels make the true ones mistrusted. However, concerning that opinion, with the occasions moving either party, we shall have place more at large to treat, if we hereafter happen to write the history of the late noble prince of famous memory, King Henry the Seventh, or perchance that history of Perkin in any compendious account by itself.\\nSummary: Section_162:  Sir James Tyrell and Dighton were both examined and confessed to murdering the two princes in the Tower. However, they could not tell where the bodies were taken. The princes were likely killed by their uncle, King Richard III, and his merciless tormentors. Text: Section_162: Very truth is it, and well known, that at such time as Sir James Tyrell was in the Tower for treason committed against the most famous prince, King Henry the Seventh both Dighton and he were examined and confessed the murder in manner above written, but to where the bodies were removed, they could nothing tell. And thus, as I have learned of them that much knew and little cause had to lie, were these two noble princes these innocent, tender children, born of most royal blood, brought up in great wealth, likely long to live, to reign, and rule in the realm by traitorous tyranny taken, deprived of their estate, swiftly shut up in prison, and privately slain and murdered, their bodies cast God knows where by the cruel ambition of their unnatural uncle and his merciless tormentors.\\nIdentification: Sections 150, Section 149, and Section_162 mentions the narrator's position on the Princes in the Tower.\\nIdentification: The narrator's beliefs concerning the deaths of the two princes can be found in Section_150, Section 149, and Section_162\\nAnswer:  The narrator believes that the two princes were killed on Richard's orders. (S.150, S.149, S.162)\\nExcellent. Let's try another.\"},\n",
        "    {\"question\": \"Question: Is Wales mentioned in the text?\", \"output\": \"Sections:\\nSummary: Section_52:  The Cardinal responded that the Council would be content if the Queen stayed with her children, but it would be better for the Duke of York to be with the King. He said that there are occasions when it is better for a child to be away from his mother, and this is one of those occasions. Text: Section_52: No man denies, good Madam, said the Cardinal, but that your Grace were of all folk most necessary about your children, and so would all the Council not only be content but also glad that you were, if it might stand with your pleasure to be in such place as might stand with their honor. But if you appoint yourself to tarry here, then think they yet more apt that the Duke of York were at his liberty honorably with the King to the comfort of them both than here as a sanctuary man to both their dishonor and obloquy. Since there is not always so great necessity to have the child be with the mother, but that occasion may sometime be such that it should be more expedient to keep him elsewhere. Which in this well appears that, at such time as your dearest son, then Prince and now King, should for his honor and good order of the country, keep household in Wales far out of your company, your Grace was well content therewith yourself./nSummary: Section_17:  After King Edward IV's death, his son Prince Edward moved towards London. He was accompanied by Sir Anthony Woodville, Lord Rivers, and other members of the queen's family. Text: Section_17: As soon as the King was departed, that noble Prince his son drew toward London, who at the time of his father's death kept household at Ludlow in Wales.  Such country, being far off from the law and recourse to justice, was begun to be far out of good will and had grown up wild with robbers and thieves walking at liberty uncorrected. And for this reason the Prince was, in the life of his father, sent thither, to the end that the authority of his presence should restrain evilly disposed persons from the boldness of their former outrages.  To the governance and ordering of this young Prince, at his sending thither, was there appointed Sir Anthony Woodville, Lord Rivers and brother unto the Queen, a right honorable man, as valiant of hand as politic in counsel. Adjoined were there unto him others of the same party, and, in effect, every one as he was nearest of kin unto the Queen was so planted next about the Prince.\\nSummary: Section_15:  On his deathbed, King Edward IV warns his people of the great hurt that could come to them if they fall into disagreement again. He urges them to love each other, for the sake of their country and their own safety. Text: Section_15: But since things passed cannot be brought back, much ought we the more beware by what occasion we have taken so great hurt before, that we soon afterwards fall not in that occasion again. Now be those griefs past, and all is (God be thanked) quiet, and likely right well to prosper in wealthful peace under your cousins, my children, if God send them life and you love. Of which two things, the less loss were they, if taken by God at his pleasure,  for yet should the realm always find kings, and by chance good kings. But if you among yourselves in a child's reign fall at debate, many a good man shall perish and perhaps he too, and you too, before this land find peace again. Wherefore in these last words that ever I look to speak with you, I exhort you and require you all, for the love that I have ever bore to you, for the love that our Lord bears to us all, from this time forward, all griefs forgotten, each of you love the other. Which I verily trust you will, if you anything earthly regard either God or your King, affinity or kindred, this realm, your own country, or your own surety.\\nIdentification: Section_52 mentions Wales in the context of the Duke of York being sent there away from his mother. Section_17 mentions Wales in the context of Prince Edward keeping household at Ludlow in Wales. Section_15 does not mention Wales.\\nAnswer: Yes, Wales is mentioned in the text in Section_52 and Section_17.\\nExcellent. Let's try another.\"}\n",
        "],\n",
        "# This how we specify how the example should be formatted.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"question: {question}\",\n",
        ")"
      ],
      "metadata": {
        "id": "lojtt-Sl9A3D"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"You are an AI expert on the 'History of Richard III' by Thomas More. Your objective is to help answer questions about this text. Using the Method below, you will answer those questions after examining sections of the text deemed the most likely to possess the answers.\\n\\nMethod:\\n\\n1. Question: You will be provided with a question.\\n2. Sections: You will be given sections of texts from Thomas More's 'The History of Richard III.' \\n3. Identification: You will identify which sections directly answers the question. If no section answers the question, offer 'None'.\\n4. Answer: You will compose a brief Answer to the Question. Only answer the question with relevant information contained in the identified Sections, and cite which sections provided evidence for your Answer.\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Question: {question}\\nIdentification:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"question\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "print(prompt_from_string_examples.format(question=\"Who was kept in the Tower?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbE_JKobBsXr",
        "outputId": "f7aab2c1-2363-48bc-f475-449709b19533"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an AI expert on the 'History of Richard III' by Thomas More. Your objective is to help answer questions about this text. Using the Method below, you will answer those questions after examining sections of the text deemed the most likely to possess the answers.\n",
            "\n",
            "Method:\n",
            "\n",
            "1. Question: You will be provided with a question.\n",
            "2. Sections: You will be given sections of texts from Thomas More's 'The History of Richard III.' \n",
            "3. Identification: You will identify which sections directly answers the question. If no section answers the question, offer 'None'.\n",
            "4. Answer: You will compose a brief Answer to the Question. Only answer the question with relevant information contained in the identified Sections, and cite which sections provided evidence for your Answer.\n",
            "\n",
            "question: output\n",
            "\n",
            "Question: Who was kept in the Tower?\n",
            "Identification:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = [prompt_near + res_string]\n",
        "print(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2I9MCGrIawW",
        "outputId": "74078209-10c6-44e1-fcde-49a299e63f6a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"You are an AI expert on the 'History of Richard III' by Thomas More. Your objective is to help answer questions about this text. Using the Method below, you will answer those questions after examining sections of the text deemed the most likely to possess the answers.\\n\\nMethod:\\n\\n1. Question: You will be provided with a question.\\n2. Sections: You will be given sections of texts from Thomas More's 'The History of Richard III.' \\n3. Identification: You will identify which sections best answer the question. If no section offers sufficient information, offer 'None'.\\n4. Answer: You will compose a brief Answer to the Question. Only answer the question with relevant information contained in the identified Sections. Provide paratheatrical citations indicating which Section is the source for that quote.\\n\\nquestion: output\\n\\nQuestion: Who is the mayor of London?\\nSections:Summary: Section_3:  King Edward IV was a good-looking and strong man who was wise in counsel and just in war. He was also known for his love of women and good food. However, he was also known to be a fair and merciful man, and he was greatly loved by his people. Text: Section_3: He was a goodly personage, and very princely to behold: of heart, courageous; politic in counsel; in adversity nothing abashed; in prosperity, rather joyful than proud; in peace, just and merciful; in war, sharp and fierce; in the field, bold and hardy, and nevertheless, no further than wisdom would, adventurous. Whose wars whosoever would well consider, he shall no less commend his wisdom when he withdrew than his manhood when he vanquished. He was of visage lovely, of body mighty, strong, and clean made; however, in his latter days with over-liberal diet , he became somewhat corpulent and burly, and nonetheless not uncomely; he was of youth greatly given to fleshly wantonness, from which health of body in great prosperity and fortune, without a special grace, hardly refrains. This fault not greatly grieved the people, for one man's pleasure could not stretch and extend to the displeasure of very many, and the fault was without violence, and besides that, in his latter days, it lessened and well left. Summary: Section_4:  King Edward IV's realm was prosperous and at peace. The people were obedient and the lords were not at variance. King Edward IV was a good king who was loved by his people. Text: Section_4: In which time of his latter days, this realm was in quiet and prosperous estate: no fear of outward enemies, no war in hand, nor none toward, but such as no man looked for; the people toward the Prince, not in a constrained fear, but in a willing and loving obedience; among themselves, the commons in good peace. The lords whom he knew at variance, he himself in his deathbed appeased. He had left all gathering of money (which is the only thing that withdraws the hearts of Englishmen from the prince), nor anything he intended to take in hand by which he should be driven thereunto, for his tribute out of France he had obtained before, and the year foregoing his death he had obtained Berwick Castle. And although throughout his reign he was with his people so benign, courteous and so familiar that no part of his virtues was more esteemed, yet that condition in the end of his days (in which many princes by a long continued sovereignty decline into a proud port from their debonair behavior at the beginning) marvelously in him grew and increased so far forth that, in the summer, the last that ever he saw, his Highness, being at Windsor hunting, sent for the Mayor and Aldermen of London to him for no other errand but to have them hunt and be merry with him. Here he treated them not so stately but so friendly and of so familiar cheer, and sent venison from there so freely into the city, that no one thing in many days before got him either more hearts or more hearty favor among the common people, who oftentimes more esteem and take for greater kindneness a little courtesy than a great benefit. Summary: Section_2:  The people's love for King Edward IV increased after his death, as many of those who bore him grudge for deposing King Henry VI were either dead or had grown into his favor. Text: Section_2: Even after his death, this favor and affection toward him because of the cruelty, mischief, and trouble of the tempestuous world that followed afterwards�increased more highly. At such time as he died, the displeasure of those that bore him grudge for King Henry's sake, the Sixth, whom he deposed, was well assuaged, and in effect quenched, in that many of them were dead in the more than twenty years of his reign�a great part of a long life. And many of them in the meantime had grown into his favor, of which he was never sparing.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "wAceLOM9A7UM"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_from_string_examples)"
      ],
      "metadata": {
        "id": "L-zEJ5_iFsCH"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(submission_text+res_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "DXt0nTNmFsKI",
        "outputId": "12b237ec-6fa4-4d37-f7e8-8e718650c7d4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Section_3, Section_7, Section_9\\nAnswer: George, Duke of Clarence, was a goodly noble prince who was known for his ambition and envy of his brother, King Edward IV. He was also known for his love of women and good food, and was greatly loved by his people. However, his ambition and envy of his brother led to his downfall, as he was accused of treason and sentenced to death. According to Section_3, King Edward IV was wise in counsel and just in war, and was known for his love of women and good food. According to Section_7, George was ambitious and envied his brother, and was ultimately sentenced to death. According to Section_9, some people think that King Edward IV had a hand in the death of his brother, George, the Duke of Clarence, as his death would clear the way for him to become king. However, there is no certainty about this, and it is just as likely that George's death was simply a coincidence.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2 - PromptChain0 - Few Shot Prompting for Text Identification Individual Outputs**"
      ],
      "metadata": {
        "id": "JSobeZEeb7rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "RgsuPMqMHH7z"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_text = \"Is Cecily discussed?\""
      ],
      "metadata": {
        "id": "f96aHWriFsNx"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cell for running OpenAI embeddings on csv file.\n",
        "import csv\n",
        "from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "#from numpy import mean\n",
        "import numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
        "\n",
        "datafile_path = \"./more_index_embeddings.csv\"  # for your convenience, we precomputed the embeddings\n",
        "df = pd.read_csv(datafile_path)\n",
        "df[\"babbage_search\"] = df.babbage_search.apply(eval).apply(np.array)\n",
        "\n",
        "def search_text(df, product_description, n=3, pprint=True):\n",
        "    embedding = get_embedding(\n",
        "        product_description,\n",
        "        engine=\"text-search-babbage-query-001\"\n",
        "    )\n",
        "    df[\"similarities\"] = df.babbage_search.apply(lambda x: cosine_similarity(x, embedding))\n",
        "\n",
        "    res = (\n",
        "        df.sort_values(\"similarities\", ascending=False)\n",
        "        .head(n)\n",
        "        .combined\n",
        "        #.combined.str.replace(\"Summary: \", \"\")\n",
        "        #.str.replace(\"Text:\", \": \")\n",
        "    )\n",
        "\n",
        "    # Create an empty list to store the outputs\n",
        "    output_list = []\n",
        "\n",
        "    for r in res:\n",
        "        # Append each output to the list\n",
        "        output_list.append(r[:500])\n",
        "        # If `pprint` is True, print the output\n",
        "        if pprint:\n",
        "            print(r[:500])\n",
        "            print()\n",
        "\n",
        "    # Return the list of outputs\n",
        "    return output_list\n",
        "\n"
      ],
      "metadata": {
        "id": "YTZFtPMBcS8F"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#begin code\n",
        "\n",
        "#cell for running OpenAI embeddings on csv file.\n",
        "import csv\n",
        "from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "#from numpy import mean\n",
        "import numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
        "\n",
        "datafile_path = \"./more_index_embeddings.csv\"  # for your convenience, we precomputed the embeddings\n",
        "df = pd.read_csv(datafile_path)\n",
        "df[\"babbage_search\"] = df.babbage_search.apply(eval).apply(np.array)\n",
        "\n",
        "def search_text(df, product_description, n=3, pprint=True):\n",
        "    embedding = get_embedding(\n",
        "        product_description,\n",
        "        engine=\"text-search-babbage-query-001\"\n",
        "    )\n",
        "    df[\"similarities\"] = df.babbage_search.apply(lambda x: cosine_similarity(x, embedding))\n",
        "\n",
        "    res = (\n",
        "        df.sort_values(\"similarities\", ascending=False)\n",
        "        .head(n)\n",
        "        .combined\n",
        "        #.combined.str.replace(\"Summary: \", \"\")\n",
        "        #.str.replace(\"Text:\", \": \")\n",
        "    )\n",
        "\n",
        "    # Create an empty list to store the outputs\n",
        "    output_list = []\n",
        "\n",
        "    for r in res:\n",
        "        # Append each output to the list\n",
        "        output_list.append(r)\n",
        "        # If `pprint` is True, print the output\n",
        "        if pprint:\n",
        "            print(r[:500])\n",
        "            print()\n",
        "\n",
        "    # Convert the list of outputs to a DataFrame\n",
        "    results_df = pd.DataFrame(output_list, columns=[\"output\"])\n",
        "\n",
        "    # Return the DataFrame of results\n",
        "    return results_df\n",
        "\n",
        "# Call the search_text() function and store the return value in a variable\n",
        "results_df = search_text(df, submission_text, n=3)\n",
        "\n",
        "output1 = results_df.iloc[0][\"output\"]\n",
        "# Access the second output as a string\n",
        "output2 = results_df.iloc[1][\"output\"]\n",
        "# Access the third output as a string\n",
        "output3 = results_df.iloc[2][\"output\"]\n",
        "\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "results_df.to_csv('results_df.csv')\n",
        "#end code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duVbRSH4-xNy",
        "outputId": "90811256-a2d3-4c40-a80f-ca80b322535d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Section_0:  King Edward IV died in 1483, leaving behind seven children. Edward, the eldest, was 13 years old at the time of his father's death. Richard, the second son, was two years younger. Elizabeth, Cecily, Brigette, Anne, and Katherine were the King's daughters. Elizabeth was later married to King Henry VII, and Anne was married to Thomas Howard, Earl of Surrey. Katherine was the last of the King's children to marry, and she eventually married a man of wealth. Text: Section_0: King\n",
            "\n",
            "Summary: Section_109:  Dame Elizabeth Lucy was brought in and sworn to tell the truth. She confessed that she and King Edward IV were never betrothed, but that he spoke to her in a way that led her to believe he would marry her. She also said that she would never have shown him kindness if he hadn't spoken to her the way he did./n Text: Section_109: Whereupon Dame Elizabeth Lucy was sent for. And although she was by the King's mother and many others filled with good encouragement�to affirm that \n",
            "\n",
            "Summary: Section_96:  King Edward IV had three concubines, one of whom was Shore's wife. The King took special pleasure in her because she was the merriest of the three. She was also content with the deed itself well done, or because she delighted to be sued unto and to show what she was able to do with the King, or because wanton and wealthy women be not always covetous. Text: Section_96: The King would say that he had three concubines in whom three diverse qualities differently excelled: one t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "burial_question = \"Summary: Section_1:  King Edward IV was a beloved king who was interred at Windsor with great honor. He was especially beloved by the people at the time of his death. Text: Section_1: This noble prince died at his palace of Westminster and, with great funeral honor and heaviness of his people from thence conveyed, was interred at Windsor. He was a king of such governance and behavior in time of peace (for in war each part must needs be another's enemy) that there was never any prince of this land attaining the crown by battle so heartily beloved by the substance of the people, nor he himself so specially in any part of his life as at the time of his death.\\nRelevance determination:\\nKey phrases and contexts: The key phrases 'interred at Windsor' and 'the time of his death' indicate the relevance of the section to the question. The context of the section, which discusses the burial of King Edward IV, also supports its relevance to the question.\\nSignificance and detail: The information in the section is significant to the question, as it provides specific details about the location of King Edward IV's burial. The section also provides detailed information about the circumstances of his burial, indicating its relevance to the question.\\nBackground knowledge and context: The historical and cultural significance of Windsor as a burial place for English monarchs may be relevant background knowledge and context to consider when evaluating the relevance of the section to the question.\\nIdentification: Section_1: Relevant. This section mentions Windsor as the burial place of King Edward IV and provides detailed information about his burial, indicating its relevance to the question.\\nExcellent. Let's try another.\"\n",
        "roman_question = \"Summary: Section_97:  Jane Shore was a woman who was in good favor with the Prince and had many friends. However, she is now in a beggarly condition. Men tend to remember those who have done them evil, and Jane Shore is an example of someone who is not remembered because she did not do anything evil. Text: Section_97: I doubt not some shall think this woman too slight a thing to be written of and set among the remembrances of great matters, which they shall specially think, that by chance esteem her only by what they now see. But to me seems the change so much the more worthy to be remembered, in how much she is now in the more beggarly condition without friends and worn out of acquaintance after good substance, after great favor with the Prince, after great suit and seeking to by all those that those days had business to speed, as many other men were in their times, who be now famous only by the infamy of their ill deeds. Her doings were not much less, although they be much less remembered because they were not so evil. For men use, if they have an evil turn, to write it in marble; and whosoever does us a good turn, we write it in dust,  which is not worst proved by her, for at this day she begs of many at this day living, that at this day had begged if she had not been.\\nRelevance determination:\\nKey phrases and contexts: There are no key phrases or contexts in the section that indicate its relevance to the question.\\nSignificance and detail: The information in the section is not directly relevant to the question, as it does not mention any ancient Romans.\\nBackground knowledge and context: There is no relevant background knowledge or context that would indicate the relevance of the section to the question.\\nIdentification: Section_97: Irrelevant. This section does not mention any ancient Romans, so it is not relevant to the question.\\nAnswer: None\\nExcellent. Let's try another.\"\n",
        "narrator_question = \"Summary: Section_8:  King Richard III was a cruel and ambitious man who was not afraid to kill those who stood in his way. He was a skilled captain in war, and he murdered King Henry VI while he was a prisoner in the Tower. Text: Section_8: Richard, the third son, of whom we now treat, was in wit and courage equal with either of them, in body and prowess far under them both: little of stature, ill featured of limbs, crooked-backed, his left shoulder much higher than his right, hard-favored in appearance, and such as is in the case of lords called warlike, in other men called otherwise. He was malicious, wrathful, envious, and from before his birth, ever perverse. It is for truth reported that the Duchess his mother had so much ado in her travail to birth him that she could not be delivered of him uncut, and he came into the world with the feet forward, as men be borne outward,  and (as the story runs) also not untoothed. Either men of hatred reported the above for truth or else nature changed her course in his beginning in the course of whose life many things were unnaturally committed. No unskilled captain was he in war, for which his disposition was more suited than for peace. Sundry victories had he, and sometimes overthrows, but never by fault of his own person, either of hardiness or political order. Free was he called when dispensing gifts, and somewhat above his power liberal; with large gifts he got for himself unsteadfast friendship, for which he was glad to pillage and spoil in other places, and get for himself steadfast hatred. He was close and secret, a deep dissembler, lowly of countenance, arrogant of heart, outwardly friendly where he inwardly hated, not omitting to kiss whom he thought to kill; pitiless and cruel, not for evil will always, but for ambition, and either for the surety or increase of his estate. Friend and foe was much the same; where his advantage grew, he spared no man death whose life withstood his purpose. He slew with his own hands King Henry the Sixth, being prisoner in the Tower, as men constantly say, and that without commandment or knowledge of the King, who would, undoubtedly, if he had intended such a thing, have appointed that butcherly office to some other than his own born brother.\\nRelevance determination:\\nKey phrases and contexts: The key phrases 'cruel and ambitious' and 'murdered King Henry VI' indicate the relevance of the section to the question. The context of the section, which discusses the character and actions of King Richard III, also supports its relevance to the question.\\nSignificance and detail: The information in the section is significant to the question, as it provides specific details about the narrator's opinion of King Richard III. The section also provides detailed descriptions of Richard III's character and actions, indicating its relevance to the question.\\nBackground knowledge and context: The historical and political context of King Richard III's reign may be relevant background knowledge and context to consider when evaluating the relevance of the section to the question.\\nIdentification: Section_8: Relevant. This section discusses the narrator's opinion of King Richard III and provides detailed descriptions of his character and actions, indicating its relevance to the question.\\nAnswer: The narrator thinks of Richard III as a cruel and ambitious man who was not afraid to kill those who stood in his way. 'He was in nature so malignant that he delighted more in the killing of beasts than in the hunting of them, and was so much the more to be feared because he was so much the more subtle in dissembling his malice. He was so much the more dangerous because he was so much the more secret. For he would never do anything openly, but always privily, insomuch that his evil deeds were not perceived till they were felt.' (S.8)\""
      ],
      "metadata": {
        "id": "tWTZEFQcgJPl"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are some examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"question\": \"Question: Where was Edward IV buried?\", \"output\": burial_question},\n",
        "    {\"question\": \"Question: What does the narrator think of Richard III?\", \"output\": narrator_question},\n",
        "    {\"question\": \"Question: Are any ancient Romans mentioned in the text?\", \"output\": roman_question}\n",
        "],\n",
        "# This how we specify how the example should be formatted.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"question: {question}\",\n",
        ")"
      ],
      "metadata": {
        "id": "gIgS3farc2t1"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"You are an AI expert on the 'History of Richard III' by Thomas More. In this exercise you are given a Section of More's text and a user supplied question. Your objective is to determine whether that Section of the text is relevant to the user question. Using the Method below, you will determine the Section's relevance to the user question.\\n\\nMethod:\\n\\n1. Question: You will be provided with a user question.\\n2. Section: You will be given a section of the text from Thomas More's 'The History of Richard III.' \\n3. Relevance determination: Generate an analysis whether the section is relevant to the user question by considering the following factors:\\nKey phrases and contexts: Identify key phrases and contexts in the section that may indicate its relevance to the question, such as references to specific locations, events, or people mentioned in the section that are related to the question.\\nSignificance and detail: Evaluate the significance of the information in the section to the question, and the level of detail provided in the section, to determine its relevance.\\nBackground knowledge and context: Incorporate background knowledge and context, such as historical or cultural information, to help understand and evaluate the relevance of the section to the question.\\n4. Identification: After providing the Relevance Determination, then indiciate if the section is relevant. If so, offer 'Section Number: Relevant'. If the section is not relevant, offer 'Section Number: Irrelevant'.\\n5. Answer: If the Section is relevant, compose a brief Answer to the Question using information from the Section. If the Section is irrevelant, answer with 'None'.\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Question: {question}\\nRelevance determination:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"question\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "print(prompt_from_string_examples.format(question=\"Who was kept in the Tower?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgv1HO7kc6Jq",
        "outputId": "03693c83-c8f9-408f-eb68-ad7c5817a4ea"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an AI expert on the 'History of Richard III' by Thomas More. In this exercise you are given a Section of More's text and a user supplied question. Your objective is to determine whether that Section of the text is relevant to the user question. Using the Method below, you will determine the Section's relevance to the user question.\n",
            "\n",
            "Method:\n",
            "\n",
            "1. Question: You will be provided with a user question.\n",
            "2. Section: You will be given a section of the text from Thomas More's 'The History of Richard III.' \n",
            "3. Relevance determination: Generate an analysis whether the section is relevant to the user question by considering the following factors:\n",
            "Key phrases and contexts: Identify key phrases and contexts in the section that may indicate its relevance to the question, such as references to specific locations, events, or people mentioned in the section that are related to the question.\n",
            "Significance and detail: Evaluate the significance of the information in the section to the question, and the level of detail provided in the section, to determine its relevance.\n",
            "Background knowledge and context: Incorporate background knowledge and context, such as historical or cultural information, to help understand and evaluate the relevance of the section to the question.\n",
            "4. Identification: After providing the Relevance Determination, then indiciate if the section is relevant. If so, offer 'Section Number: Relevant'. If the section is not relevant, offer 'Section Number: Irrelevant'.\n",
            "5. Answer: If the Section is relevant, compose a brief Answer to the Question using information from the Section. If the Section is irrevelant, answer with 'None'.\n",
            "\n",
            "question: output\n",
            "\n",
            "Question: Who was kept in the Tower?\n",
            "Relevance determination:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "I3F4o49Gc_Cf"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_from_string_examples)"
      ],
      "metadata": {
        "id": "m3JQeCX7c_pR"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_check_1 = chain.run(submission_text+output1)\n",
        "print(r_check_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJVTuy_idBuq",
        "outputId": "50f0e9b5-c92b-4e95-e2b9-e02b24f138fa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This section is relevant to the question as it mentions Cecily, one of the King's daughters, and provides some detail about her, such as her lack of fortune compared to her beauty.\n",
            "\n",
            "Section_0: Relevant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_check_2 = chain.run(submission_text+output2)\n",
        "print(r_check_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3yDhvg0HQFo",
        "outputId": "7add080e-7e08-4885-d601-e042099b7e70"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This section is relevant to the question as it mentions Cecily, the mother of King Edward IV, who is mentioned in the question. The section also provides detail about the relationship between King Edward IV and Dame Elizabeth Lucy, which is relevant to the question.\n",
            "Identification: Section_109: Relevant\n",
            "Answer: Dame Elizabeth Lucy confessed that she and King Edward IV were never betrothed, but that he spoke to her in a way that led her to believe he would marry her. Cecily, the mother of King Edward IV, was mentioned in the section.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_check_3 = chain.run(submission_text+output3)\n",
        "print(r_check_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2GjOqG5HT_F",
        "outputId": "83ae954a-4a7c-40b5-c30e-978ae1778f64"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This section does not mention Cecily, but it does provide information about the King's concubines, one of whom is Shore's wife. The section provides detail about the King's pleasure in Shore's wife and her ability to influence the King's decisions. This information is relevant to the question as it provides context about the King's relationships with his concubines.\n",
            "Section_96: Relevant.\n",
            "Answer: King Edward IV had three concubines, one of whom was Shore's wife. He took special pleasure in her and she was able to influence his decisions. Cecily is not mentioned in this section.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3 - PromptChain0 - Passing on Relevant Sections to Generate Composite Answers w/ Quotation**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Yj9N-WCGZu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#combined function for combining sections + outputs, and then filtering via regex for relevant sections\n",
        "#don't delete\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# combined function for combining sections + outputs, and then filtering via regex for relevant sections\n",
        "\n",
        "combined_df = pd.DataFrame(columns=['output', 'r_check'])\n",
        "combined_df['output'] = [output1, output2, output3]\n",
        "combined_df['r_check'] = [r_check_1, r_check_2, r_check_3]\n",
        "\n",
        "# Use the re.IGNORECASE flag to make the regular expression case-insensitive\n",
        "regex = re.compile(r'(section_\\d+:\\srelevant)', re.IGNORECASE)\n",
        "\n",
        "# Apply the regex pattern to the 'r_check' column and store the results in a new 'mask' column\n",
        "combined_df['mask'] = combined_df['r_check'].str.extract(regex).get(0).notnull()\n",
        "\n",
        "# Create a second mask to capture \"this is relevant\"\n",
        "combined_df['second_mask'] = combined_df['r_check'].str.contains(r'this section is relevant', flags=re.IGNORECASE)\n",
        "\n",
        "# Combine the two masks using the bitwise OR operator (|) and store the result in the 'mask' column\n",
        "combined_df['mask'] = combined_df['mask'] | combined_df['second_mask']\n",
        "\n",
        "# Filter the combined dataframe to include only rows where the 'mask' column is True\n",
        "relevant_df = combined_df.loc[combined_df['mask']].copy()\n",
        "\n",
        "# Check if there are any rows in the relevant_df dataframe\n",
        "if relevant_df.empty:\n",
        "    # If there are no rows, print the desired message\n",
        "    print(\"No relevant sections identified.\")\n",
        "else:\n",
        "    # Otherwise, continue with the rest of the script\n",
        "\n",
        "    def combine_strings(row):\n",
        "        return row['output'] + '\\nSection Analysis\\n' + row['r_check']\n",
        "\n",
        "    # Use the apply function to apply the combine_strings function to each row of the relevant_df dataframe\n",
        "    # and assign the result to the 'combined_string' column\n",
        "    relevant_df['combined_string'] = relevant_df.apply(combine_strings, axis=1)\n",
        "\n",
        "    final_sections = relevant_df['combined_string']\n",
        "    #final_sections.to_csv('final_sections.csv')\n",
        "\n",
        "    evidence_df = pd.DataFrame(final_sections)\n",
        "\n",
        "    evidence = '\\n\\n'.join(evidence_df['combined_string'])\n",
        "    evidence_df.to_csv('evidence.csv')\n",
        "\n",
        "    evidence_objects = []\n",
        "\n",
        "    # Iterate over the rows in the evidence_df dataframe\n",
        "    for index, row in evidence_df.iterrows():\n",
        "        # Convert the value in the 'combined_string' column to a string\n",
        "        evidence_object = str(row['combined_string'])\n",
        "        # Append the evidence object to the list of evidence objects\n",
        "        evidence_objects.append(evidence_object)\n",
        "\n",
        "    #evidence_0 = evidence_objects[0]\n",
        "    #evidence_1 = evidence_objects[1]\n",
        "    #evidence_2 = evidence_objects[2]\n",
        "\n",
        "    # Print the list of evidence objects\n",
        "    #print(evidence_objects)\n",
        "\n",
        "\n",
        "\n",
        "    # Get the value in the first row of the 'combined_string' column of the evidence_df dataframe\n",
        "    #evidence_0 = evidence_df.loc[0, 'combined_string']\n",
        "    #evidence_1 = evidence_df.loc[0, 'combined_string']\n",
        "    #evidence_2 = evidence_df.loc[0, 'combined_string']\n",
        "\n",
        "    # Convert the value to a string\n",
        "    #evidence_0 = str(evidence_0)\n",
        "\n",
        "    print(evidence)\n",
        "    #print(evidence_objects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-s3zBefJ935",
        "outputId": "cbad3696-84c0-4c43-977c-415e311d36b7"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Section_47:  The clergy agree with Henry Strafford that a sanctuary man should be delivered in payment of his debts and only have the liberty to get his living with the labor of his hands. Text: Section_47: And that diversity of the clergy that were present, whether they said it for his pleasure or, as they thought, agreed plainly that by the law of God and of the church the goods of a sanctuary man should be delivered in payment of his debts, and stolen goods to the owner, and only liberty reserved him to get his living with the labor of his hands.\n",
            "Section Analysis\n",
            " This section does not mention monks specifically, but does mention the clergy, which could be interpreted as a reference to monks. The section also discusses the law of God and the church, which could be related to the role of monks in the church.\n",
            "Significance and detail: The section does not provide much detail about the role of monks, but does provide some context about the law of God and the church, which could be related to the role of monks.\n",
            "Background knowledge and context: Monks were an important part of the church in the time of Richard III, and were often involved in religious and legal matters.\n",
            "Identification: Section_47: Relevant\n",
            "Answer: Monks are not mentioned directly in this section, but the clergy are mentioned, and the law of God and the church are discussed, which could be related to the role of monks in the church.\n",
            "\n",
            "Summary: Section_171:  Bishop John Morton and Henry Strafford were discussing the recent reigns of kings. Morton said that he had originally wished for King Henry's son to have the crown, but after King Edward IV won the crown, he was faithful to him. Strafford asked Morton about his opinion of the late Protector and now King, and Morton said that he had already meddled too much with the world and would from that day meddle with his book and his beads alone. Text: Section_171: For when the Duke first began to praise and boast of the King and show how much profit the realm should take by his reign, my Lord Morton answered, Surely, my Lord, folly it were for me to lie, for if I would swear the contrary, your Lordship would not, I know, believe it, but that, if the world would have gone as I would have wished, King Henry's son had had the crown and not King Edward. But after God had ordered him to lose it, and King Edward to reign, I was never so mad that I would with a dead man strive against the living. So was I to King Edward faithful chaplain, and glad would have been that his child had succeeded him. However, if the secret judgment of God has otherwise provided, I propose not to spurn against a spur, nor labor to set up what God pulls down. And as for the late Protector and now King. . . .� And even there he left off, saying that he had already meddled too much with the world and would from that day meddle with his book and his beads alone, and no further.\n",
            "Section Analysis\n",
            " Key phrases and contexts: The section mentions King Edward IV, King Henry's son, the late Protector and now King, and the phrase \"his book and his beads alone\". These phrases indicate that the section may be relevant to the question as they suggest the presence of religious figures. Significance and detail: The section provides a detailed description of the conversation between Bishop John Morton and Henry Strafford, and the opinion of Morton on the late Protector and now King. This suggests that the section is relevant to the question. Background knowledge and context: The phrase \"his book and his beads alone\" is a reference to monks, suggesting that the section is relevant to the question.\n",
            "Identification: Section_171: Relevant\n",
            "Answer: Bishop John Morton mentioned that the late Protector and now King had already meddled too much with the world and would from that day meddle with his book and his beads alone, a reference to monks.\n",
            "\n",
            "Summary: Section_101: Two friars gave sermons in praise of the Protector, one before and one after the coronation. Both sermons were so full of flattery that they lost their audiences. Friar Penker's sermon was so tedious that he lost his voice and had to stop in the middle. Doctor Shaa's sermon was so dishonest that he lost his reputation and soon after his life. However, some people think that Penker was not involved in the matter before the coronation, and that he only started flattering the Protector afterwards. It is certain that Doctor Shaa was involved in the beginning, and that he was the one who broke the news to the people in a sermon at Paul's Cross. Text: Section_101: Of these two, the one had a sermon in praise of the Protector before the coronation, the other after; both so full of tedious flattery that no man's ears could abide them. Penker in his sermon so lost his voice that he was glad to leave off and come down in the midst. Doctor Shaa by his sermon lost his honesty and soon after his life, for very shame of the world, into which he dared never after come abroad. But the friar cared not for shame, and so it harmed him the less. However, some doubt and many think that Penker was not of counsel of the matter before the coronation, but after the common manner fell to flattery afterwards; namely, because his sermon was not immediately after it, but at Saint Mary's Hospital on the Easter after. But certain is it that Doctor Shaa was of counsel in the beginning so far forth that they determined he should first break the matter in a sermon at Paul's Cross, in which he should, by the authority of his preaching, incline the people to the Protector's ghostly purpose.\n",
            "Section Analysis\n",
            " This section mentions two friars, Penker and Doctor Shaa, who gave sermons in praise of the Protector before and after the coronation. It is certain that Doctor Shaa was involved in the beginning and that he was the one who broke the news to the people in a sermon at Paul's Cross. However, some doubt that Penker was involved in the matter before the coronation. This section is relevant to the question as it mentions two friars and provides details about their involvement in the Protector's coronation.\n",
            "\n",
            "Section_101: Relevant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pyl8JgenQl2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "c1ks26xIQl5i"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu6vzr06Ql8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Continue - prepare prompt for compositie answer*"
      ],
      "metadata": {
        "id": "7hkAMyR6kWxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "canterbury_analysis = \"Relevant Sections & Section Analyses\\nSummary: Section_169:  Bishop John Morton was a man of great wit and learning who was loyal to the House of Lancaster. He was content to receive King Edward IV's pardon and became one of his trusted advisors. Morton was later made Archbishop of Canterbury and Chancellor of England. He lived a long and prosperous life before dying a godly death. Text: Section_169: The Bishop was a man of great natural wit, very well learned, and honorable in behavior, lacking no wise ways to win favor. He had been loyal to the part of King Henry while that part was in wealth, and nevertheless left it not, nor forsook it in woe, but fled the realm with the Queen and the Prince,  and while King Edward had the King  in prison, he never came home but to the battlefield.  After this loss, and that part was utterly subdued, King Edward, for Morton's steadfast faith and wisdom, not only was content to receive him, but also wooed him to come and had him from thence forth both in secret trust and very special favor, in which he nothing deceived. For he was, as you have heard, after King Edward's death, first taken by the tyrant for his loyalty to the King, but found the means to turn this Duke to his plans, joining gentlemen together in the aid of King Henry, devising first the marriage between him and King Edward's daughter, by which he declared his faith and good service to both his masters at once, with infinite benefit to the realm, by the conjunction of those two bloods in one, whose several titles had long left the land without quiet. Afterwards, he fled the realm, went to Rome, never minding more to meddle with the world till the noble prince, King Henry the Seventh, got him home again, made him Archbishop of Canterbury and Chancellor of England, whereunto the Pope joined the honor of Cardinal. Thus living many days in as much honor as one man might well wish, ended them so godly that his death, with God's mercy, well changed his life. This man, therefore, as I was about to tell you, by long and often alternate proof, as well from prosperity as adverse fortune, had gotten by great experience, the very mother and mistress of wisdom, a deep insight in political, worldly drifts.\\nSection Analysis\\nThis section is relevant to the user question as it provides detailed information about the character of Archbishop John Morton. It mentions his loyalty to the House of Lancaster, his wisdom and learning, his trustworthiness and favor with King Edward IV, and his godly death. This information is significant to the user question and provides a clear picture of the Archbishop's character.\\nSection_169: Relevant\\nSummary: Section_39:  Archbishop Thomas Rotherham defends sanctuary, saying that it is a sacred place that should not be disturbed for any earthly reason. He says that he will do his best to obtain what they want from the queen, but that her fear is the only impediment. Text: Section_39: And therefore, said the Archbishop of Canterbury, God forbid that any man should for any earthly enterprise break the immunity and liberty of that sacred sanctuary that has been the safeguard of so many a good man's life. And I trust, said he, with God's grace, we shall not need it. But for any manner need, I would not we should do it. I trust that she shall be with reason contented, and all things in good manner obtained. And if it happen that I bring it not so to pass, yet shall I toward it so far forth do my best, that you shall all well perceive that no lack of my dutiful efforts, but the mother's dread and womanish fear, shall be the impediment.\\nSection Analysis\\nThis section is relevant to the user question as it mentions the Archbishop of Canterbury and provides some insight into his character. The Archbishop is portrayed as a defender of sanctuary and someone who is willing to do his best to obtain what the people want from the queen. This indicates that he is a character of integrity and loyalty.\\nAnswer: The Archbishop of Canterbury is portrayed as a character of integrity and loyalty, as he is willing to do his best to obtain what the people want from the queen and defends the sacred sanctuary of the church.\\nSummary: Section_27:  Archbishop Thomas Rotherham was greatly concerned when he heard that the Queen was sending all her belongings to sanctuary. He went to her and found her surrounded by her belongings, with people coming and going. Text: Section_27: Notwithstanding, sir, said he, my Lord sends your Lordship word that there is no fear, for he assures you that all shall be well. I assure him, said the Archbishop, be it as well as it will, it will never be so well as we have seen it. And thereupon, by and by, after the messenger departed, he caused in all the haste all his servants to be called up, and so with his own household about him, and every man armed, he took the Great Seal  with him, and came yet before day unto the Queen. About whom he found much heaviness, rumble, haste and business, carriage and conveyance of her stuff into sanctuary chests, coffers, packs, bundles, trusses, all on men's backs, no man unoccupied; some loading, some going, some discharging, some coming for more, some breaking down the walls to bring in the shortest way, and some yet drew to them that helped to carry the wrong way.\\nSection Analysis: This section is relevant to the user question as it provides information about the character of the Archbishop of Canterbury. The section mentions that the Archbishop was greatly concerned when he heard that the Queen was sending her belongings to sanctuary and that he took the Great Seal with him and came before day to the Queen. This indicates that the Archbishop was a loyal and devoted servant to the Queen, and was willing to go to great lengths to protect her.\\nSection_27: Relevant\\n Final Answer:\\n Archbishop Thomas Rotherham of Canterbury is portrayed as a character of great loyalty and integrity in Thomas More's 'The History of Richard III.' In Section_27, the Archbishop is described as taking the Great Seal with him and visiting the Queen before daybreak in order to protect her belongings. In Section_39, he defends the sacred sanctuary of the church, saying that no man should break its immunity and liberty for any earthly enterprise. John Morton, another Archbishop of Canterbury, is also depicted as a man of great natural wit, very well learned, and honorable in behavior, as seen in Section_169. He remained loyal to King Henry even during times of adversity, and fled the realm with the Queen and Prince. Thus, both Archbishops are depicted as being deeply committed to the protection and well-being of the royal family.\\nExcellent. Let's try another.\",\n",
        "#roman_question = \"Summary: Section_97:  Jane Shore was a woman who was in good favor with the Prince and had many friends. However, she is now in a beggarly condition. Men tend to remember those who have done them evil, and Jane Shore is an example of someone who is not remembered because she did not do anything evil. Text: Section_97: I doubt not some shall think this woman too slight a thing to be written of and set among the remembrances of great matters, which they shall specially think, that by chance esteem her only by what they now see. But to me seems the change so much the more worthy to be remembered, in how much she is now in the more beggarly condition without friends and worn out of acquaintance after good substance, after great favor with the Prince, after great suit and seeking to by all those that those days had business to speed, as many other men were in their times, who be now famous only by the infamy of their ill deeds. Her doings were not much less, although they be much less remembered because they were not so evil. For men use, if they have an evil turn, to write it in marble; and whosoever does us a good turn, we write it in dust,  which is not worst proved by her, for at this day she begs of many at this day living, that at this day had begged if she had not been.\\nRelevance determination:\\nKey phrases and contexts: There are no key phrases or contexts in the section that indicate its relevance to the question.\\nSignificance and detail: The information in the section is not directly relevant to the question, as it does not mention any ancient Romans.\\nBackground knowledge and context: There is no relevant background knowledge or context that would indicate the relevance of the section to the question.\\nIdentification: Section_97: Irrelevant. This section does not mention any ancient Romans, so it is not relevant to the question.\\nAnswer: None\\nExcellent. Let's try another.\"\n",
        "#narrator_question = \"Summary: Section_8:  King Richard III was a cruel and ambitious man who was not afraid to kill those who stood in his way. He was a skilled captain in war, and he murdered King Henry VI while he was a prisoner in the Tower. Text: Section_8: Richard, the third son, of whom we now treat, was in wit and courage equal with either of them, in body and prowess far under them both: little of stature, ill featured of limbs, crooked-backed, his left shoulder much higher than his right, hard-favored in appearance, and such as is in the case of lords called warlike, in other men called otherwise. He was malicious, wrathful, envious, and from before his birth, ever perverse. It is for truth reported that the Duchess his mother had so much ado in her travail to birth him that she could not be delivered of him uncut, and he came into the world with the feet forward, as men be borne outward,  and (as the story runs) also not untoothed. Either men of hatred reported the above for truth or else nature changed her course in his beginning in the course of whose life many things were unnaturally committed. No unskilled captain was he in war, for which his disposition was more suited than for peace. Sundry victories had he, and sometimes overthrows, but never by fault of his own person, either of hardiness or political order. Free was he called when dispensing gifts, and somewhat above his power liberal; with large gifts he got for himself unsteadfast friendship, for which he was glad to pillage and spoil in other places, and get for himself steadfast hatred. He was close and secret, a deep dissembler, lowly of countenance, arrogant of heart, outwardly friendly where he inwardly hated, not omitting to kiss whom he thought to kill; pitiless and cruel, not for evil will always, but for ambition, and either for the surety or increase of his estate. Friend and foe was much the same; where his advantage grew, he spared no man death whose life withstood his purpose. He slew with his own hands King Henry the Sixth, being prisoner in the Tower, as men constantly say, and that without commandment or knowledge of the King, who would, undoubtedly, if he had intended such a thing, have appointed that butcherly office to some other than his own born brother.\\nRelevance determination:\\nKey phrases and contexts: The key phrases 'cruel and ambitious' and 'murdered King Henry VI' indicate the relevance of the section to the question. The context of the section, which discusses the character and actions of King Richard III, also supports its relevance to the question.\\nSignificance and detail: The information in the section is significant to the question, as it provides specific details about the narrator's opinion of King Richard III. The section also provides detailed descriptions of Richard III's character and actions, indicating its relevance to the question.\\nBackground knowledge and context: The historical and political context of King Richard III's reign may be relevant background knowledge and context to consider when evaluating the relevance of the section to the question.\\nIdentification: Section_8: Relevant. This section discusses the narrator's opinion of King Richard III and provides detailed descriptions of his character and actions, indicating its relevance to the question.\\nAnswer: The narrator thinks of Richard III as a cruel and ambitious man who was not afraid to kill those who stood in his way. 'He was in nature so malignant that he delighted more in the killing of beasts than in the hunting of them, and was so much the more to be feared because he was so much the more subtle in dissembling his malice. He was so much the more dangerous because he was so much the more secret. For he would never do anything openly, but always privily, insomuch that his evil deeds were not perceived till they were felt.' (S.8)\""
      ],
      "metadata": {
        "id": "j9-EfIs_p672"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final answer prompt experiment.0 - includes final quotations, has problem completing output (token length?)\n",
        "# These are some examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"question\": \"Question: What kind of character did the Archbishop of Canterbury have?\", \"output\": canterbury_analysis},\n",
        "    #{\"question\": \"Question: What does the narrator think of Richard III?\", \"output\": narrator_question},\n",
        "    #{\"question\": \"Question: Are any ancient Romans mentioned in the text?\", \"output\": roman_question}\n",
        "],\n",
        "# This how we specify how the example should be formatted.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"question: {question}\",\n",
        ")"
      ],
      "metadata": {
        "id": "o-_jBTFboCrH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final answer prompt experiment.0 - includes final quotations, has problem completing output (token length?)\n",
        "#don't delete\n",
        "\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"You are an AI expert on the 'History of Richard III' by Thomas More. In this exercise you are given a user supplied question, relevant Section(s) from More's text, and analysis of the Section(s)’s relevance to the question. Based on this information, your objective is to compose a skillfully written answer synthesizing the information contained in the relevant Section(s) using the Method below, you will determine the Section's relevance to the user question.\\nMethod:\\n1. Question: You will be provided with a user question.\\n2. Relevant Section(s): You will be given Relevant Section(s) of the text from Thomas More's 'The History of Richard III.' Each Relevant Section also contains a Section Analysis.\\n3. Section Analysis: You are then provided an analysis of each Section’s relevance to the Question.\\n4. Chronological Order: Generate the numerical order of the Sections. The Section number indicates their location in More's text. Lower Section numbers generally means that information is chronologically earlier than higher Section numbers.\\n4. Supporting Quotation(s): Identify brief quotations from the Section:Text portions of the Relevant Section(s) that support the Combined Answer. Provide parenthetical citations for the sections used - such as (S.9) for Section_9. Order these Supporting Quotation(s) in Chronological Order.\\n4. Final Answer: Based on the information contained in the Relevant Section(s), Section Analyses, and Supporting Quotation(s), compose a well-written and evocative Final Answer that follows Chronological Order. This Final Answer should employ information from each of the Relevant Sections, and include appropriate Supporting Quotation(s). Include the parenthetical citations in this Final Answer.\\nLet’s begin.\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Question: {question}\\nChronological Order:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"question\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "print(prompt_from_string_examples.format(question=\"Who was kept in the Tower?\"))"
      ],
      "metadata": {
        "id": "rXn31XDooGpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final answer prompt experiment.1 - no full quotation for final answer\n",
        "#don't delete\n",
        "\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=example_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix=\"You are an AI expert on the 'History of Richard III' by Thomas More. In this exercise you are given a user supplied question, relevant Section(s) from More's text, and analysis of the Section(s)’s relevance to the question. Based on this information, your objective is to compose a skillfully written answer synthesizing the information contained in the relevant Section(s) using the Method below, you will determine the Section's relevance to the user question.\\nMethod:\\n1. Question: You will be provided with a user question.\\n2. Relevant Section(s): You will be given Relevant Section(s) of the text from Thomas More's 'The History of Richard III.' Each Relevant Section also contains a Section Analysis.\\n3. Section Analysis: You are then provided an analysis of each Section’s relevance to the Question.\\n4. Chronological Order: Generate the numerical order of the Sections. The Section number indicates their location in More's text. Lower Section numbers generally means that information is chronologically earlier than higher Section numbers.\\n4. Final Answer: Based on the information contained in the Relevant Section(s) and Section Analyses, and Supporting Quotation(s), compose a well-written and evocative Final Answer that follows Chronological Order. This Final Answer should employ information from each of the Relevant Sections, and include appropriate supporting quotation(s) for the Summary:Text sections of the Relevant Sections. Also include in the Final Answer parenthetical citations from the sections and quotations used - such as (S.9) for Section_9. Order these sections and quotation(s) in Chronological Order.\\nLet’s begin.\\n\",\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Question: {question}\\nChronological Order:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=[\"question\"],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "print(prompt_from_string_examples.format(question=\"Who was kept in the Tower?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOWuyVg_2JWD",
        "outputId": "f4d0d0bc-6930-4c86-998a-a660f2e84752"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an AI expert on the 'History of Richard III' by Thomas More. In this exercise you are given a user supplied question, relevant Section(s) from More's text, and analysis of the Section(s)’s relevance to the question. Based on this information, your objective is to compose a skillfully written answer synthesizing the information contained in the relevant Section(s) using the Method below, you will determine the Section's relevance to the user question.\n",
            "Method:\n",
            "1. Question: You will be provided with a user question.\n",
            "2. Relevant Section(s): You will be given Relevant Section(s) of the text from Thomas More's 'The History of Richard III.' Each Relevant Section also contains a Section Analysis.\n",
            "3. Section Analysis: You are then provided an analysis of each Section’s relevance to the Question.\n",
            "4. Chronological Order: Generate the numerical order of the Sections. The Section number indicates their location in More's text. Lower Section numbers generally means that information is chronologically earlier than higher Section numbers.\n",
            "4. Final Answer: Based on the information contained in the Relevant Section(s) and Section Analyses, and Supporting Quotation(s), compose a well-written and evocative Final Answer that follows Chronological Order. This Final Answer should employ information from each of the Relevant Sections, and include appropriate supporting quotation(s) for the Summary:Text sections of the Relevant Sections. Also include in the Final Answer parenthetical citations from the sections and quotations used - such as (S.9) for Section_9. Order these sections and quotation(s) in Chronological Order.\n",
            "Let’s begin.\n",
            "\n",
            "\n",
            "question: output\n",
            "\n",
            "Question: Who was kept in the Tower?\n",
            "Chronological Order:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "jXubTG0up_-K"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_from_string_examples)"
      ],
      "metadata": {
        "id": "NC_p8dThqDjY"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_analysis = chain.run(submission_text+evidence)\n",
        "print(final_analysis)\n",
        "\n",
        "with open(\"final_analysis.txt\", \"w\") as file:\n",
        "  file.write(final_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74e84ptoqG2g",
        "outputId": "dc72a17f-c899-4373-e020-abacdb389227"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Section_47, Section_171, Section_101\n",
            "\n",
            "Answer: Monks are mentioned in Thomas More's 'The History of Richard III' in the form of two friars, Penker and Doctor Shaa. In Section_47, the clergy agree with Henry Strafford that a sanctuary man should be delivered in payment of his debts and only have the liberty to get his living with the labor of his hands. This suggests that monks were involved in religious and legal matters. In Section_171, Bishop John Morton said that he had already meddled too much with the world and would from that day meddle with his book and his beads alone, a reference to monks. Finally, in Section_101, two friars gave sermons in praise of the Protector, one before and one after the coronation. It is certain that Doctor Shaa was involved in the beginning and that he was the one who broke the news to the people in a sermon at Paul's Cross. However, some doubt that Penker was involved in the matter before the coronation (S.47, S.171, S.101).\n"
          ]
        }
      ]
    }
  ]
}